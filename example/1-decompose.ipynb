{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639542e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T08:49:08.791369Z",
     "start_time": "2025-09-27T08:49:08.765815Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c101a479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T08:49:09.237369Z",
     "start_time": "2025-09-27T08:49:08.973279Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90df03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T08:49:11.983943Z",
     "start_time": "2025-09-27T08:49:09.742333Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from emgdv_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bebf4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T08:49:11.989149Z",
     "start_time": "2025-09-27T08:49:11.985631Z"
    }
   },
   "outputs": [],
   "source": [
    "SIL_THRESH = 0.93\n",
    "PNR_THRESH = 10\n",
    "CoV_THRESH = 2\n",
    "\n",
    "MIN_PEAKS_SRC = 30\n",
    "\n",
    "N_COMPONENTS = 300  #0  # maximum number of attempts to detect MU\n",
    "N_ITERATIONS = 100  # maximum iterations during MU detection attempt\n",
    "\n",
    "lowcut, highcut = 30, 400  #lowcut, highcut = 20, 500  # as in Farina tutorial\n",
    "apply_butterworth_filter = True\n",
    "\n",
    "notch_filter_hz = 50\n",
    "apply_notch_filter = True\n",
    "\n",
    "apply_wavelet_filter = False\n",
    "apply_zscore = True\n",
    "apply_winsorize = False\n",
    "\n",
    "MIN_STANDALONE = MIN_PEAKS_SRC\n",
    "SENSITIVITY_STANDALONE = 1.5\n",
    "# mu considered identical if their firings ts overlap in 30% of time +-1 ts. Negro advocates for 0.3\n",
    "DROP_ROA = 0.3\n",
    "\n",
    "cluster_method = 'k-means'\n",
    "\n",
    "extension_method = 'spline'\n",
    "apply_extension = True\n",
    "NUM_EXTEND = SPLINE_DEGREE = 72\n",
    "\n",
    "WHITEN_SOLVER = 'eigh'  # svd\n",
    "\n",
    "FS = 2222\n",
    "FORCE_CHANNEL_FIRST = True\n",
    "\n",
    "save_json = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88cd3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T08:49:12.004326Z",
     "start_time": "2025-09-27T08:49:11.990601Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def run(FILE, PREFIX):\n",
    "\n",
    "    data = pd.read_csv(FILE)\n",
    "\n",
    "    name = FILE.split('/')[-1].split('_')[0]\n",
    "    results_save_path = f'{PREFIX}{name}'\n",
    "\n",
    "    os.makedirs(results_save_path, exist_ok=True)\n",
    "    os.makedirs(results_save_path + '/bin/', exist_ok=True)\n",
    "    os.makedirs(results_save_path + '/AP/raw/', exist_ok=True)\n",
    "    os.makedirs(results_save_path + '/AP/smooth/', exist_ok=True)\n",
    "\n",
    "    ch_lens = []\n",
    "    for col in list(data):\n",
    "        l = len(data[col].dropna())\n",
    "        ch_lens.append(l)\n",
    "\n",
    "    ch_len = max(ch_lens)\n",
    "    for col in list(data):\n",
    "        data[col] = scipy_signal.resample(data[col].dropna(), ch_len)\n",
    "\n",
    "    if not FORCE_CHANNEL_FIRST:\n",
    "        FORCE_CHANNEL = data.abs().mean(axis=1).values\n",
    "    else:\n",
    "        FORCE_CHANNEL = data.iloc[:, 0].dropna().values\n",
    "        data = data.iloc[:, 1:]\n",
    "\n",
    "    for ch, y in enumerate(data.T.values):\n",
    "        N = len(y)\n",
    "        yf = rfft(y)\n",
    "        xf = rfftfreq(N, 1 / FS)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "        ax.plot(xf, np.abs(yf), color='darkred')\n",
    "        ax.set_xlabel('Frequency, Hz', labelpad=0)\n",
    "        ax.set_ylabel('Amplitude', labelpad=0)\n",
    "        ax.tick_params(pad=0)\n",
    "        ax.set_title(f'CH{ch+1}')\n",
    "        plt.savefig(\n",
    "            f'{results_save_path}/CH{ch+1}-frequencies-spectrum-raw.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    FORCE_CHANNEL = moving_average(FORCE_CHANNEL, FS)\n",
    "    FORCE_CHANNEL[FORCE_CHANNEL < 0] = 0\n",
    "\n",
    "    force_min = np.quantile(FORCE_CHANNEL, 0.01)\n",
    "    force_max = np.quantile(FORCE_CHANNEL, 0.99)\n",
    "\n",
    "    FORCE_CHANNEL = ((FORCE_CHANNEL - force_min) /\n",
    "                     (force_max - force_min)) * 100\n",
    "    FORCE_CHANNEL[FORCE_CHANNEL < 0] = 0\n",
    "\n",
    "    SIGNAL = copy.deepcopy(data.T.values)\n",
    "    CH, TS = SIGNAL.shape\n",
    "    RMS = (((SIGNAL.T).T**2).mean(axis=0))**0.5\n",
    "    RMS = moving_average(RMS, FS)\n",
    "\n",
    "    if apply_winsorize:\n",
    "        data = skew_filter(data, FS, 3)\n",
    "        \n",
    "    SIGNAL = copy.deepcopy(data.T.values)\n",
    "\n",
    "    for ch_row in range(CH):\n",
    "\n",
    "        s = moving_average(SIGNAL[ch_row, :], 3)\n",
    "        if apply_butterworth_filter:\n",
    "            s = butterworth_filter(s, lowcut, highcut, FS, order=2)\n",
    "        if apply_notch_filter:\n",
    "\n",
    "            if not apply_butterworth_filter:\n",
    "                y = butterworth_filter(s)\n",
    "            else:\n",
    "                y = s\n",
    "\n",
    "            N = len(y)\n",
    "            yf = rfft(y)\n",
    "            xf = rfftfreq(N, 1 / FS)\n",
    "\n",
    "            mn = np.mean(np.abs(yf))\n",
    "            sd = np.std(np.abs(yf))\n",
    "            r = mn + sd * 10\n",
    "\n",
    "            while np.max(np.abs(yf)) > r:\n",
    "                N = len(y)\n",
    "                yf = rfft(y)\n",
    "                xf = rfftfreq(N, 1 / FS)\n",
    "                notch_filter_hz = xf[np.argmax(np.abs(yf))]\n",
    "                print('powerlinepeak:', notch_filter_hz)\n",
    "                s = y = notch_filter(s, FS, notch_filter_hz)\n",
    "\n",
    "        if apply_wavelet_filter:\n",
    "            s = wavelet_filter(s.reshape(1, -1)).flatten()\n",
    "\n",
    "        SIGNAL[ch_row, :] = s\n",
    "\n",
    "    DATA_FILTERED = copy.deepcopy(SIGNAL)\n",
    "\n",
    "    SHAPE = np.array([6, CH / 2])\n",
    "    fig, axes = plt.subplots(CH, 1, sharey=True, sharex=True, figsize=SHAPE)\n",
    "    sns.despine()\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    for ch_row, ax in enumerate(axes):\n",
    "        ax.plot(SIGNAL[ch_row, :], lw=1, color='k')\n",
    "        ax.set_ylabel(f'CH{ch_row}')\n",
    "        ax.set_yticklabels([])\n",
    "        ax.tick_params(pad=0)\n",
    "        ax.set_ylabel(ax.get_ylabel(), labelpad=0)\n",
    "\n",
    "    ax.set_xlabel('Time (samples)')\n",
    "\n",
    "    plt.savefig(f'{results_save_path}/data-channels.pdf',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    if apply_zscore:\n",
    "        scaler = StandardScaler()\n",
    "        SIGNAL = scaler.fit_transform(SIGNAL.T).T\n",
    "\n",
    "    if apply_extension:\n",
    "        spline = None\n",
    "        if extension_method == 'spline':\n",
    "\n",
    "            spline = SplineTransformer(degree=SPLINE_DEGREE,\n",
    "                                       n_knots=SPLINE_DEGREE + 1,\n",
    "                                       extrapolation='periodic',\n",
    "                                       knots='quantile',\n",
    "                                       include_bias=True)\n",
    "\n",
    "            SIGNAL = spline.fit_transform(SIGNAL.T).T\n",
    "\n",
    "        if extension_method == 'extend':\n",
    "            SIGNAL = extend(SIGNAL, NUM_EXTEND)\n",
    "\n",
    "    SIGNAL = whiten(SIGNAL, WHITEN_SOLVER)\n",
    "    \n",
    "    keep = []\n",
    "    for i in range(SIGNAL.shape[0]):\n",
    "        if len(np.unique(SIGNAL[i, :])) < 10:\n",
    "            continue\n",
    "        keep.append(i)\n",
    "\n",
    "    SIGNAL = SIGNAL[keep, :]\n",
    "    \n",
    "\n",
    "    data_filtered = pd.DataFrame(DATA_FILTERED.T)\n",
    "    data_filtered.columns = [f'ch{k+1}' for k in range(data_filtered.shape[1])]\n",
    "    data_filtered['force_channel'] = FORCE_CHANNEL\n",
    "    data_filtered.to_csv(f'{results_save_path}/data-prepared.csv.gz',\n",
    "                         decimal='.',\n",
    "                         sep=',',\n",
    "                         index=False,\n",
    "                         compression='gzip')\n",
    "\n",
    "    for ch, y in enumerate(DATA_FILTERED):\n",
    "        N = len(y)\n",
    "        yf = rfft(y)\n",
    "        xf = rfftfreq(N, 1 / FS)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "        ax.plot(xf, np.abs(yf), color='darkred')\n",
    "        ax.set_xlabel('Frequency, Hz', labelpad=0)\n",
    "        ax.set_ylabel('Amplitude', labelpad=0)\n",
    "        ax.tick_params(pad=0)\n",
    "        ax.set_title(f'CH{ch+1}')\n",
    "        plt.savefig(f'{results_save_path}/CH{ch+1}-frequencies-spectrum.png',\n",
    "                    dpi=300,\n",
    "                    bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "    print(SIGNAL.shape)\n",
    "    WEIGHTS, SOURCES_INFO, DCR = fastICA(\n",
    "        SIGNAL,\n",
    "        N_COMPONENTS,\n",
    "        sil_thresh=SIL_THRESH,\n",
    "        pnr_thresh=PNR_THRESH,\n",
    "        cov_thresh=CoV_THRESH,\n",
    "        iterations_main=N_ITERATIONS,\n",
    "        MIN_PEAKS_SRC=MIN_PEAKS_SRC,\n",
    "        FS=FS,\n",
    "        MIN_STANDALONE=MIN_STANDALONE,\n",
    "        SENSITIVITY_STANDALONE=SENSITIVITY_STANDALONE,\n",
    "        DROP_ROA=DROP_ROA,\n",
    "        cluster_method=cluster_method)\n",
    "\n",
    "    MU_FOUND = len(SOURCES_INFO)\n",
    "\n",
    "    res, stage_res = get_stats_sources_info_full(SOURCES_INFO, FORCE_CHANNEL,\n",
    "                                                 RMS, TS, FS, {})\n",
    "\n",
    "    res.to_excel(f'{results_save_path}/statistics.xlsx')\n",
    "\n",
    "    if MU_FOUND > 0:\n",
    "\n",
    "        try:\n",
    "            plot_regression(results_save_path, res)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        try:\n",
    "            plot_raster(results_save_path, FS, TS, SOURCES_INFO, FORCE_CHANNEL,\n",
    "                        cluster_method, extension_method)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        try:\n",
    "            plot_ap_raw(results_save_path, CH, FS, MU_FOUND, DATA_FILTERED,\n",
    "                        SOURCES_INFO)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        try:\n",
    "            plot_ap_smooth(results_save_path, CH, FS, MU_FOUND, DATA_FILTERED,\n",
    "                           SOURCES_INFO)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    joblib.dump(spline, results_save_path + '/bin/spline.bin')\n",
    "    joblib.dump(scaler, results_save_path + '/bin/zscorer.bin')\n",
    "    joblib.dump(WEIGHTS, results_save_path + '/bin/WEIGHTS.bin')\n",
    "    sources_info = [{'mu_ts': src['mu_ts']} for src in SOURCES_INFO]\n",
    "    joblib.dump(sources_info, results_save_path + '/bin/sources_info.bin')\n",
    "    joblib.dump(DCR, results_save_path + '/bin/DCR.bin')\n",
    "    joblib.dump(FORCE_CHANNEL, results_save_path + '/bin/FORCE_CHANNEL.bin')\n",
    "    joblib.dump(keep, results_save_path + '/bin/KEEP_CHANNEL.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630afad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T08:49:12.490224Z",
     "start_time": "2025-09-27T08:49:12.478538Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c6ec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T10:12:41.080194Z",
     "start_time": "2025-09-27T08:49:12.643617Z"
    }
   },
   "outputs": [],
   "source": [
    "run_durations = []\n",
    "\n",
    "FILES1 = glob.glob('raw_data/rep1/*.csv')\n",
    "PREFIX1 = 'decomposition/rep1/'\n",
    "\n",
    "FILES2 = glob.glob('raw_data/rep2/*.csv')\n",
    "PREFIX2 = 'decomposition/rep2/'\n",
    "\n",
    "for FILE1, FILE2 in list(zip(FILES1, FILES2))[:]:\n",
    "\n",
    "    for FILE, PREFIX in zip([FILE1, FILE2], [PREFIX1, PREFIX2]):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        name = FILE.split('/')[-1].split('_')[0]\n",
    "        print(name)\n",
    "        run(FILE, PREFIX)\n",
    "        run_duration = time.time() - start_time\n",
    "        print(run_duration/60)\n",
    "        run_durations.append(run_duration)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da15821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T10:12:41.086467Z",
     "start_time": "2025-09-27T10:12:41.082180Z"
    }
   },
   "outputs": [],
   "source": [
    "run_durations = np.array(run_durations)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67020b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T10:12:41.093049Z",
     "start_time": "2025-09-27T10:12:41.087840Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_median(x, precision=1):\n",
    "    q25 = round(np.nanquantile(x, 0.25), precision)\n",
    "    q50 = round(np.nanquantile(x, 0.5), precision)\n",
    "    q75 = round(np.nanquantile(x, 0.75), precision)\n",
    "    r = f\"{q50}[{q25}-{q75}]\"\n",
    "    return r\n",
    "\n",
    "f_median(run_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a209e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T10:39:01.245672Z",
     "start_time": "2025-09-25T10:39:01.238593Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782fd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6414352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fefdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03dbe30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14798c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e786e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1556d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
